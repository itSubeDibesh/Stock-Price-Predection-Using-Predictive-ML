{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:110px\">\n",
    "    <a href=\"https://www.ismt.edu.np/\">\n",
    "        <img src=\"./docs/ismt.png\" alt=\"ismt College\"  height=\"100\" align=\"left\">\n",
    "    </a>\n",
    "    <a href=\"https://www.sunderland.ac.uk/\">\n",
    "        <img src=\"./docs/sunderland.png\" alt=\"University of Sunderland\" align=\"right\" height=\"100\" >\n",
    "    </a>\n",
    "    <div align=\"center\"><h3><b>Stock Price Prediction Using Machine Learning Algorithms</b></h3><p><b><a href=\"https://github.com/itSubeDibesh\">Dibesh Raj Subedi</a></b></p></div>\n",
    "</div>\n",
    "\n",
    "# **Stock Price Prediction Using Machine Learning Algorithms**\n",
    "\n",
    "- **Student Name:** [Dibesh Raj Subedi](https://github.com/itSubeDibesh)\n",
    "- **Student ID:** 219327253\n",
    "- **Module Name:** Artificial Intelligence\n",
    "- **Module Code:** CET313\n",
    "- **Module Leader / Module Tutor:** [Mr. Himalayan Kashyapati](https://www.youtube.com/channel/UCxOGD9bX_533jPWXfz8smlQ)\n",
    "- **Center:** [ISMT College](https://www.ismt.edu.in/)\n",
    "- **Programme:** BSC. (Hons) Computer Systems Engineering\n",
    "- **Project:** Stock Price Prediction Using Machine Learning Algorithms\n",
    "\n",
    "[![wakatime](https://wakatime.com/badge/github/itSubeDibesh/StockPricePredection.svg)](https://wakatime.com/badge/github/itSubeDibesh/StockPricePredection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Table of Contents_**\n",
    "\n",
    "- Introduction\n",
    "- Package Setups and Imports\n",
    "  - Dependencies Installation\n",
    "  - Import Libraries\n",
    "- Data Extraction\n",
    "  - Data Extraction Function\n",
    "    - From NEPSE\n",
    "    - From SmartWealthPro\n",
    "    - From NepaliPaisa\n",
    "  - Data Mining\n",
    "    - Data Extraction from Nepse, SmartWealthPro and NepaliPaisa\n",
    "- Data Preprocessing\n",
    "  - Citizen Investment Trust (CIT)\n",
    "  - Nabil Bank (NABIL)\n",
    "  - Nepal Life Insurance (NLIC)\n",
    "- Stock Price Prediction\n",
    "  - Using Linear Regression\n",
    "  - Using Random Forest\n",
    "  - Using LSTM\n",
    "- Comparison of models\n",
    "- Evaluation of models\n",
    "  - Accuracy\n",
    "  - Confusion Matrix\n",
    "  - Classification Report\n",
    "  - ROC Curve\n",
    "  - Precision-Recall Curve\n",
    "  - ROC-AUC Curve\n",
    "  - Precision-Recall-AUC Curve\n",
    "- Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Stock** or **Equity** a part of company plays a **significant** role in the market, reflecting the value of company and also **stating** a source of income for it's investors. Price of share or equity is affected by many factors such as market conditions, economic conditions, government policies, etc. Stock Market and Stock price prediction has been a **lucrative** subject of study for decades. Although there are several factors affecting the price of share or equity, we can observe **several patterns** over long period of time creating an **opportunity of investment**. Being a passive investor myself, the objective of this project is to **predict** the stock price of a company using **Machine Learning** techniques and explore possibilities of using different ML models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Setups and Imports\n",
    "\n",
    "Installing Dependencies and Importing Libraries Web Scraping üï∏, Data Processingüìà and Data Visualizationüìä.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies Installation üì¶üõ†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in d:\\python\\python39\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\python\\python39\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in d:\\python\\python39\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\python\\python39\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\python39\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\python\\python39\\lib\\site-packages (from requests) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\python39\\lib\\site-packages (from requests) (2021.5.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: urllib3 in d:\\python\\python39\\lib\\site-packages (1.26.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: html5lib in d:\\python\\python39\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in d:\\python\\python39\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in d:\\python\\python39\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in d:\\python\\python39\\lib\\site-packages (1.21.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in d:\\python\\python39\\lib\\site-packages (1.3.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\python\\python39\\lib\\site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\python\\python39\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in d:\\python\\python39\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.16 in d:\\python\\python39\\lib\\site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\python\\python39\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\python\\python39\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\python\\python39\\lib\\site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in d:\\python\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in d:\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\python\\python39\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in d:\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.21.2)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction\n",
    "%pip install beautifulsoup4\n",
    "%pip install requests\n",
    "%pip install urllib3\n",
    "%pip install html5lib\n",
    "# Data Manipulation\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "# Data Visualization\n",
    "%pip install matplotlib\n",
    "# Machine Learning\n",
    "%pip install sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries ‚¨áüì¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import requests\n",
    "import urllib3\n",
    "import json\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# File Handling\n",
    "import os\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# Machine Learning\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "\n",
    "To implement ML modules we need dataset and I will be using **Nepal Stock Exchange**([NEPSE](http://www.nepalstock.com)) and [SmartWealthPro](https://app.smartwealthpro.com) website to scrape dataset.\n",
    "\n",
    "Useful request types to make web and api requests for data extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request List\n",
    "REQUESTS = [\"GET\", \"POST\"]\n",
    "\n",
    "# Request type dictionary\n",
    "REQUEST_TYPE = {\n",
    "    \"GET\": REQUESTS[0],\n",
    "    \"POST\": REQUESTS[1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction Functions üìÉüï∏\n",
    "\n",
    "To extract/mine data I have defined functions to scrape and invoke intercepted api request's from [NEPSE](http://www.nepalstock.com) and [SmartWealthPro](https://app.smartwealthpro.com).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From [NEPSE](http://www.nepalstock.com)\n",
    "\n",
    "After reading [Quassarian Viper](https://q-viper.github.io/2020/11/21/deploying-nepse-data-visualizer-on-heroku/)'s post I found an data extraction method from [Nepse](http://www.nepalstock.com) website and created functions respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nepse_company_names(save_to_csv: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Extracts all the company names from NEPSE website\n",
    "\n",
    "    Args:\n",
    "        save_to_csv: Save the data to csv file - Ex: True\n",
    "\n",
    "    Return:\n",
    "        DataFrame of the company names\n",
    "\n",
    "    \"\"\"\n",
    "    http = urllib3.PoolManager()\n",
    "    http.headers.update({'User-Agent': 'Mozilla/5.0'})\n",
    "    web_page = http.request(\n",
    "        method=REQUEST_TYPE[\"GET\"],\n",
    "        url=\"http://www.nepalstock.com/company?_limit=500\"\n",
    "    )\n",
    "    soup = BS(web_page.data, 'html5lib')\n",
    "    table = soup.find('table')\n",
    "    company = []\n",
    "    rows = [row.findAll('td') for row in table.findAll('tr')[1:-2]]\n",
    "    col = 0\n",
    "    notfirstrun = False\n",
    "    for row in rows:\n",
    "        companydata = []\n",
    "        for data in row:\n",
    "            if col == 5 and notfirstrun:\n",
    "                companydata.append(data.a.get('href').split('/')[-1])\n",
    "            else:\n",
    "                companydata.append(data.text.strip())\n",
    "            col += 1\n",
    "        company.append(companydata)\n",
    "        col = 0\n",
    "        notfirstrun = True\n",
    "    status = web_page.status\n",
    "    print(\n",
    "        f\"Status Code: {status}, NEPSE Mining Company List ‚õè Status: {'Success' if status==200 else 'Failed'}\")\n",
    "    df = pd.DataFrame(company[1:], columns=company[0])\n",
    "    df.rename(columns={'Operations': 'Symbol No'}, inplace=True)\n",
    "    df.drop(columns='', inplace=True)\n",
    "    df.drop(columns='S.N.', inplace=True)\n",
    "\n",
    "    if(save_to_csv):\n",
    "        path = './NepseDataset'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        df.to_csv(path+'/company_list.csv', index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From [SmartWealthPro](https://app.smartwealthpro.com/)\n",
    "\n",
    "Although [Data Extraction From Nepse Website](#data-extraction-from-nepalipaisa-website-üìÉ) didn't helped [only for cross validating SmartWealthPro NepseId with Nepse symbol No] much, I found a way to extract data from **paid application**. Firstly, I registered for **Free Trial** on [SmartWealthPro](https://app.smartwealthpro.com) and used [Postman](https://www.postman.com/)'s **Interceptor** to intercept request and response from browser using [Postman](https://www.postman.com/)'s [Interceptor Plugin](https://chrome.google.com/webstore/detail/postman-interceptor/aicmkgpgakddgnaphhhpliifpcfhicfo) and extracted useful URL's along with cookies and imported the request code from postman to python and created respective function which would also store dataset on local drive as csv file.\n",
    "\n",
    "‚ÑπÔ∏è **NOTE:** If a failure or **_401_** status is shown it means the cookie has expired and you need to re-login and extract cookie again from [SmartWealthPro](https://app.smartwealthpro.com).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercepted Cookie of SmartWealthPro from browser\n",
    "COOKIE = \".AspNetCore.Antiforgery.c2MYB_mZqSE=CfDJ8PqVbBoQk65Ji_IQLqiq9W-fOAB5lXkNnLsOdVX_JuYMqnfZdsfQpxhsB_koNdcHbjTS7EKhCsR3Ba0H5eJRCxJYUuF2L2XjMEEsr_lEk0vHcjJbv49IaArGuxzUyEmYBJOaL7GPu4btgEc-6lC39M8; .AspNetCore.Identity.Application=CfDJ8PqVbBoQk65Ji_IQLqiq9W-MNL-VXNllti2wpkpsv9cA8u0kKTKvIGBYkW90A7ni7DpinfIjU2u4puqWHy6fidF0JFbXquKH6q_0wQDTCpB7htmSMnHIkEDijflIUm5tb7zwvETb5wxZ35xV6Q_EjusY0yFyLa-n6ogBJ0j_HDSr2NhyooqZ-dTVOSDyyAi327YiZ_decvG2QFdUOJKUY2MYGwTP3RDhoPDgJyBENNjxgi2QhpnIwGrcmKImFNK2TBpiewXgp_WUJqoHnQFJ5yHCjKW-D59ErSmauHSAXvMnidOAe9BUXVlY3FOgdoEESu4GZAYMMVyByQA8Kc5v8b-MEetPqhqBPTkezn20BaEAG9E5TfCowQmdWzlOYbiDdjlx8JKdHM-TE5gFBtTagEv21qMi83t8tXZP11HF2vZ12zap620XeyDuRS0R8KItA0Lkwc_iUhPPVIiUH9ve61VVNGZD98FCnbGx9DjFlgPX2ONOhz6DBpJp7BWxztF8NRaKzJmnpAMta-ej9ZYw60ONMW2_4r_BEeLvka6_2VOhlI7-O1CopnusQ4oJ11V1wFCX3EfJQ_7vkvKqcsFIV3M3EYWEVD-KY4s8yN9r3tY9RbWnaOpXWSLRr8bE9jRRiddjHmc5o1Ix3zBT66wkpq2Vj8saytK_oHmyM88WPMQmtwZpCuix6wT1BaHHDDaM3putb9FxUEMGrFC6I8A-5IS7p5TIEdUo_nmByI9XsgnKyzD_ACmqhm4MNrRR4r3zAU-8igzRhrT9PptJDe8vIZ-yz6BqqZXYWPyE8kjxTjR2gk7ul4zd0v309RSCLO5FilbVknSwliy1rPIXyVZhCZE\"\n",
    "\n",
    "# Request headers payload\n",
    "headers = {\n",
    "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"99\", \"Microsoft Edge\";v=\"99\"',\n",
    "    'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "    'Content-Type': 'application/json; charset=utf-8',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36 Edg/99.0.1150.55',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'Cookie': COOKIE\n",
    "}\n",
    "\n",
    "\n",
    "def smart_wealth_company_list(save_to_csv=False) -> pd.DataFrame:\n",
    "    \"\"\" Retrives List of Company from SmartWealthPro which includes CompanyId Defined by SmartWealthPro and also help's to export as csv file.\n",
    "\n",
    "    Args:\n",
    "        save_to_csv: (bool) - Ex : True\n",
    "    Returns:\n",
    "        df: (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    url = \"https://app.smartwealthpro.com/api/GetAutoCompleteCompanies?_=1648523415665\"\n",
    "    payload = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    print(\n",
    "        f\"Status Code: {response.status_code}, SmartWealthPro Mining Company List ‚õè Status: {'Success' if response.status_code==200 else 'Failed'}\")\n",
    "    if response.status_code == 200:\n",
    "        SMARTWEALTH_JSON = json.loads(response.text)\n",
    "        df = pd.DataFrame(SMARTWEALTH_JSON[\"result\"])\n",
    "        df.drop(columns='type', inplace=True)\n",
    "        df.rename(columns={'companyId': 'CompanyId', 'nepseCompanyId': 'NepseId',\n",
    "                           'companyName': 'Company', 'stockSymbol': 'Symbol', 'sector': 'Sector'}, inplace=True)\n",
    "        if save_to_csv:\n",
    "            path = \"./SmartWealthDataset\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            df.to_csv(path + '/smartwealthpro_company_list.csv', index=False)\n",
    "        return df\n",
    "    else:\n",
    "        print(\n",
    "            f\"Status Code: {response.status_code}, SmartWealthPro Mining Company List ‚õè Status: {'Success' if response.status_code==200 else 'Failed'}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def smart_wealth_company_history(companyId: str, startDate: str = \"\", endDate: str = \"\", save_to_csv=False) -> pd.DataFrame:\n",
    "    \"\"\" Fetch Company History from SmartWealthPro.\n",
    "\n",
    "    Args:\n",
    "        companyId: (str) - Ex : 154\n",
    "\n",
    "        startDate: (str) - Ex : \"2010-01-01\" (YYYY-MM-DD)\n",
    "\n",
    "        endDate: (str) - Ex : \"2020-01-01\"  (YYYY-MM-DD)\n",
    "\n",
    "        save_to_csv: (bool) - Ex : True\n",
    "\n",
    "    Returns:\n",
    "        df: (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    url = \"https://app.smartwealthpro.com/api/GetDailyHistoricalData?type=stock&id=\"+companyId+\"&fromDate=\" + \\\n",
    "        startDate+\"&toDate=\"+endDate + \\\n",
    "        \"&pageNo=1&itemsPerPage=9000000&pagePerDisplay=5&_=1648522274261\"\n",
    "    payload = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    print(\n",
    "        f\"Status Code: {response.status_code}, SmartWealthPro Mining Company ID: {companyId} ‚õè Status: {'Success' if response.status_code==200 else 'Failed'}\")\n",
    "    if response.status_code == 200:\n",
    "        SMARTWEALTH_JSON = json.loads(response.text)\n",
    "        df = pd.DataFrame(SMARTWEALTH_JSON[\"result\"]['data'])\n",
    "        df.drop(columns='sNo', inplace=True)\n",
    "        df.rename(columns={'tradeDate': 'Date', 'open': 'Open',\n",
    "                  'high': 'High', 'low': 'Low', 'close': 'Close'}, inplace=True)\n",
    "        df.insert(\n",
    "            0, 'Symbol', SMARTWEALTH_JSON[\"result\"]['summary']['stockSymbol'])\n",
    "        if save_to_csv:\n",
    "            path = \"./SmartWealthDataset/Company\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            df.to_csv(path+'/smartwealthpro_' +\n",
    "                      SMARTWEALTH_JSON[\"result\"]['summary']['stockSymbol']+'_history.csv', index=False)\n",
    "        return df\n",
    "    else:\n",
    "        print(\n",
    "            f\"Status Code: {response.status_code}, SmartWealthPro Mining Company ID: {companyId} ‚õè Status: {'Success' if response.status_code==200 else 'Failed'}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def smart_wealth_company_code(symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns CompanyCode as per SmartWealthPro using stock symbol.\n",
    "\n",
    "    Args:\n",
    "        symbol: (str) - Ex : \"AHPC\"\n",
    "    Returns:\n",
    "        companyCode: (str) - Ex : \"154\"\n",
    "    \"\"\"\n",
    "    cvs_file = pd.read_csv(\n",
    "        './SmartWealthDataset/smartwealthpro_company_list.csv')\n",
    "    return cvs_file[cvs_file['Symbol'] == symbol]['CompanyId'].values[0].__str__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From [NepaliPaisa](https://nepalipaisa.com)\n",
    "\n",
    "Data Extracted From SmartWealthPro only includes Open High Low Close(OHLC) and Data so, to make a rich dataset, information extracted from Nepali Paisa will will be added to SmartWealthPro data based on Date which will be stored as csv file for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nepali_paisa_history(symbol: str, starting_date: str = \"\", ending_date: str = \"\", save_to_csv=False):\n",
    "    \"\"\" Fetch Company History from NepaliPaisa.\n",
    "\n",
    "    Args:\n",
    "        symbol: (str) - Ex : AHPC\n",
    "\n",
    "        startDate: (str) - Ex : \"2010-01-01\" (YYYY-MM-DD)\n",
    "\n",
    "        endDate: (str) - Ex : \"2020-01-01\"  (YYYY-MM-DD)\n",
    "\n",
    "        save_to_csv: (bool) - Ex : True\n",
    "\n",
    "    Returns:\n",
    "        df: (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    url = \"https://nepalipaisa.com/Modules/GraphModule/webservices/MarketWatchService.asmx/GetTodaySharePrices\"\n",
    "    payload = \"{\\\"fromdate\\\":\\\"\"+starting_date+\"\\\",\\\"toDate\\\":\\\"\"+ending_date + \\\n",
    "        \"\\\",\\\"stockSymbol\\\":\\\"\"+symbol+\"\\\",\\\"offset\\\":1,\\\"limit\\\":90000}\"\n",
    "    headers = {\n",
    "        'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"99\", \"Microsoft Edge\";v=\"99\"',\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "        'Content-Type': 'application/json; charset=UTF-8',\n",
    "        'X-Requested-With': 'XMLHttpRequest',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36 Edg/99.0.1150.52',\n",
    "        'sec-ch-ua-platform': '\"Windows\"'\n",
    "    }\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    print(f\"Status Code: {response.status_code}, NepaliPaisa Mining Company ID: {symbol} ‚õè Status: {'Success' if response.status_code==200 else 'Failed'}\")\n",
    "    if response.status_code == 200:\n",
    "        NEPALI_PAISA_JSON = json.loads(response.text)\n",
    "        df = pd.DataFrame(NEPALI_PAISA_JSON[\"d\"])\n",
    "        df.drop(columns='__type', inplace=True)\n",
    "        df.drop(columns='AsOfDate', inplace=True)\n",
    "        df.drop(columns='AsOfDateString', inplace=True)\n",
    "        df.rename(columns={'AsOfDateShortString': 'Date', 'MaxPrice': 'High',\n",
    "                  'MinPrice': 'Low', 'ClosingPrice': 'Close', 'StockSymbol': 'Symbol'}, inplace=True)\n",
    "        if save_to_csv:\n",
    "            path = \"./NepaliPaisa/Company\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            df.to_csv(path+'/nepalipaisa_' + symbol +\n",
    "                      '_history.csv', index=False)\n",
    "        return df\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mining ‚õè\n",
    "\n",
    "After defining function to extract data from **NEPSE** and **SmartWealthPro** websites, I invoked functions and extracted dataset and also stored it on csv file locally for data storage and easy manipulation.\n",
    "\n",
    "‚ÑπÔ∏è **NOTE:** Make yore your internet is connected while mining data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Extraction from [Nepse](http://www.nepalstock.com), [SmartWealthPro](https://app.smartwealthpro.com) and [NepaliPaisa](https://nepalipaisa.com).\n",
    "\n",
    "Data Extraction from **NEPSE** and **SmartWealthPro**, **NepaliPaisa** along with cross validation of **NEPSE** data with **SmartWealthPro** data and data merge with **NepaliPaisa** data based on Symbol and Date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200, NEPSE Mining Company List ‚õè Status: Success\n",
      "Status Code: 200, SmartWealthPro Mining Company List ‚õè Status: Success\n",
      "CIT with 231 is in SMART_WEALTH_COMPANY_LIST and exists in NEPSE_COMPANY_LIST\n",
      "Status Code: 200, SmartWealthPro Mining Company ID: 231 ‚õè Status: Success\n",
      "Status Code: 200, NepaliPaisa Mining Company ID: CIT ‚õè Status: Success\n",
      "NABIL with 27 is in SMART_WEALTH_COMPANY_LIST and exists in NEPSE_COMPANY_LIST\n",
      "Status Code: 200, SmartWealthPro Mining Company ID: 27 ‚õè Status: Success\n",
      "Status Code: 200, NepaliPaisa Mining Company ID: NABIL ‚õè Status: Success\n",
      "NLIC with 251 is in SMART_WEALTH_COMPANY_LIST and exists in NEPSE_COMPANY_LIST\n",
      "Status Code: 200, SmartWealthPro Mining Company ID: 251 ‚õè Status: Success\n",
      "Status Code: 200, NepaliPaisa Mining Company ID: NLIC ‚õè Status: Success\n"
     ]
    }
   ],
   "source": [
    "# Selecting Company - Company Selection from NEPSE_COMPANY_LIST using Company Symbol\n",
    "# NABIL is one of the top Banks of Nepal,\n",
    "# NEPAL Life Insurance Corporation(NLIC) is one of the leading Life Insurance company and\n",
    "# Citizen Investment Trust(CIT) is an government company with a good market share.\n",
    "\n",
    "selected_company_symbol = [\"CIT\", \"NABIL\", \"NLIC\"]\n",
    "starting_date = \"2000-01-01\"\n",
    "ending_date = \"2022-12-31\"\n",
    "\n",
    "\n",
    "# Mining Nepse Company List\n",
    "NEPSE_COMPANY_LIST = nepse_company_names(save_to_csv=True)\n",
    "\n",
    "\n",
    "# Mining SmartWealthPro for Company List\n",
    "SMART_WEALTH_COMPANY_LIST = smart_wealth_company_list(save_to_csv=True)\n",
    "\n",
    "# Extracting Company Code of Selected Companies\n",
    "selected_company_code = [smart_wealth_company_code(\n",
    "    symbol) for symbol in selected_company_symbol]\n",
    "\n",
    "# Cross Validation of Company SymbolNo of NEPSE_COMPANY_LIST and SMART_WEALTH_COMPANY_LIST\n",
    "for symbol, code in zip(selected_company_symbol, selected_company_code):\n",
    "    if symbol not in NEPSE_COMPANY_LIST['Stock Symbol'].values and code not in SMART_WEALTH_COMPANY_LIST['NepseId'].values:\n",
    "        print(\n",
    "            f\"{symbol} with {code} is not in SMART_WEALTH_COMPANY_LIST but exists in NEPSE_COMPANY_LIST\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"{symbol} with {code} is in SMART_WEALTH_COMPANY_LIST and exists in NEPSE_COMPANY_LIST\")\n",
    "        # Mining Company History From SmartWealthPro\n",
    "        smart_wealth_company_history(companyId=smart_wealth_company_code(\n",
    "            symbol), startDate=starting_date, endDate=ending_date, save_to_csv=True)\n",
    "        nepali_paisa_history(symbol=symbol, starting_date=starting_date,\n",
    "                             ending_date=ending_date, save_to_csv=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Protocol Initiated\n",
      "Creating Directory ./FinalDataSet\n",
      "Merging ./NepaliPaisa/Company/nepalipaisa_CIT_history.csv and ./SmartWealthDataset/Company/smartwealthpro_CIT_history.csv\n",
      "Merged ./NepaliPaisa/Company/nepalipaisa_CIT_history.csv and ./SmartWealthDataset/Company/smartwealthpro_CIT_history.csv\n",
      "Merging ./NepaliPaisa/Company/nepalipaisa_NABIL_history.csv and ./SmartWealthDataset/Company/smartwealthpro_NABIL_history.csv\n",
      "Merged ./NepaliPaisa/Company/nepalipaisa_NABIL_history.csv and ./SmartWealthDataset/Company/smartwealthpro_NABIL_history.csv\n",
      "Merging ./NepaliPaisa/Company/nepalipaisa_NLIC_history.csv and ./SmartWealthDataset/Company/smartwealthpro_NLIC_history.csv\n",
      "Merged ./NepaliPaisa/Company/nepalipaisa_NLIC_history.csv and ./SmartWealthDataset/Company/smartwealthpro_NLIC_history.csv\n",
      "Merging Protocol Completed\n"
     ]
    }
   ],
   "source": [
    "# Data Merging and Actual Data Set Creation\n",
    "\n",
    "# Defining Paths\n",
    "Nepali_Paisa_Path = \"./NepaliPaisa/Company/\"\n",
    "Smart_Wealth_Path = \"./SmartWealthDataset/Company/\"\n",
    "\n",
    "# Extracting Files From Paths\n",
    "Nepali_Paisa_Files = [Nepali_Paisa_Path +\n",
    "                      file for file in os.listdir(Nepali_Paisa_Path) if file.endswith(\".csv\")]\n",
    "Smart_Wealth_Path = [Smart_Wealth_Path +\n",
    "                     file for file in os.listdir(Smart_Wealth_Path) if file.endswith(\".csv\")]\n",
    "\n",
    "if(len(Nepali_Paisa_Files) != len(Smart_Wealth_Path)):\n",
    "    print(\"Files are not equal\")\n",
    "else:\n",
    "    print(\"Merging Protocol Initiated\")\n",
    "    Data_Set_Path = \"./FinalDataSet\"\n",
    "    # Create Dir If Not Exists\n",
    "    if not os.path.exists(Data_Set_Path):\n",
    "        print(\"Creating Directory \" + Data_Set_Path)\n",
    "        os.makedirs(Data_Set_Path)\n",
    "    for nepaliPaisa, smartWealthPro in zip(Nepali_Paisa_Files, Smart_Wealth_Path):\n",
    "        print(f\"Merging {nepaliPaisa} and {smartWealthPro}\")\n",
    "        # Merge Names\n",
    "        merge_name = nepaliPaisa.split(\n",
    "            \"/\")[-1].split(\".\")[0].replace(\"nepalipaisa_\", \"\")\n",
    "        # Merge Output\n",
    "        merge = pd.merge(pd.read_csv(nepaliPaisa), pd.read_csv(smartWealthPro), on=[\n",
    "                         \"Date\", \"High\", \"Low\", \"Close\", \"Symbol\"], how=\"inner\")\n",
    "        merge.to_csv(Data_Set_Path+\"/\"+merge_name+\".csv\", index=False)\n",
    "        print(f\"Merged {nepaliPaisa} and {smartWealthPro}\")\n",
    "    print(\"Merging Protocol Completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citizen Investment Trust (CIT)\n",
    "\n",
    "‚ÑπÔ∏è **NOTE:** Data Fetched from **SmartWealthPro** website is arranged on descending **_Date_** so, I reversed the order of the dataframe to get data in ascending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Data from CSV\n",
    "CIT = pd.read_csv(\n",
    "    './FinalDataSet/CIT_history.csv')[::-1].reset_index(drop=True)\n",
    "# Getting type of data\n",
    "print(\"TYPE: \", type(CIT))\n",
    "# Getting shape of data\n",
    "print(\"SHAPE: \", CIT.shape)\n",
    "# Getting Head of data\n",
    "CIT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing Data Info\n",
    "CIT.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Statics of data\n",
    "CIT.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting DateTimeIndex of Data\n",
    "CIT.set_index(pd.DatetimeIndex(CIT['Date']), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Data Graph of Closing Price\n",
    "CIT['Close'].plot(figsize=(16, 8), ylabel=\"Price in Rs.\",\n",
    "                  xlabel=\"Date\", title=\"CIT Closing Price\", legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding EMA to Dataframe by appending\n",
    "\n",
    "# CIT.ta.ema(close=\"Close\", length=10, append=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIT.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NULL EMA\n",
    "# CIT= CIT.iloc[10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIT.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIT[\"Close\"].plot(figsize=(16, 8), ylabel=\"Price in Rs.\", xlabel=\"Date\",  legend=True, color=\"orange\")\n",
    "# CIT[\"EMA_10\"].plot(figsize=(16, 8), ylabel=\"Price in Rs.\", xlabel=\"Date\",  legend=True, color=\"black\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nabil Bank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nepal Life Insurance Corporation (NLIC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Price Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citizen Investment Trust (CIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into Train and Test\n",
    "X_Train, X_Test, Y_Train, Y_TEST = model_selection.train_test_split(\n",
    "    CIT[[\"Close\"]], CIT[[\"EMA_10\"]], test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traning Set\n",
    "X_Train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST Set\n",
    "X_Test.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Linear Regression Model\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Training Model\n",
    "model.fit(X_Train, Y_Train)\n",
    "\n",
    "# Use the model to make predictions\n",
    "Y_Prediction = model.predict(X_Test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC Curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall-AUC Curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcf1d46d271c46101d6967829d4a5f475342a2ce08e4944f989fbcdc9bb23690"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
